import numpy as np
import pandas as pd
PREVIOUS_MAX_ROWS = pd.options.display.max_rows
pd.options.display.max_rows = 25
pd.options.display.max_columns = 20
pd.options.display.max_colwidth = 82
np.random.seed(12345)
import matplotlib.pyplot as plt
plt.rc("figure", figsize=(10, 6))
np.set_printoptions(precision=4, suppress=True)


import numpy as np
import pandas as pd


# Tạo một đối tượng Series (một cấu trúc dữ liệu 1 chiều) của Pandas.
# Series này chứa 4 giá trị: 1.2, -3.5, một giá trị thiếu (Not a Number - NaN) và 0.
float_data = pd.Series([1.2, -3.5, np.nan, 0])

# In ra nội dung của Series vừa tạo.
# Kết quả hiển thị cả giá trị và kiểu dữ liệu (float64).
float_data


float_data.isna() # Kiểm tra giá trị thiếu (NaN): Trả về Series Boolean (True/False) cho biết phần tử nào là NaN.


# Khởi tạo Series chuỗi chứa các giá trị bình thường, np.nan và None
string_data = pd.Series(["aardvark", np.nan, None, "avocado"])
string_data # Hiển thị Series (NaN và None đều được hiển thị là NaN)
string_data.isna() # Kiểm tra giá trị thiếu (NaN/None): Trả về Series Boolean, đánh dấu True cho cả np.nan và None.

# Khởi tạo Series số thập phân, giá trị None tự động chuyển thành NaN
float_data = pd.Series([1, 2, None], dtype='float64')
float_data # Hiển thị Series (None được chuyển thành NaN)
float_data.isna() # Kiểm tra giá trị thiếu (NaN): Trả về Series Boolean, đánh dấu True cho NaN.


# Tạo một Series Pandas chứa các số và các giá trị thiếu (NaN)
data = pd.Series([1, np.nan, 3.5, np.nan, 7])

# Loại bỏ các giá trị thiếu (NaN): Trả về một Series mới CHỈ chứa các giá trị hợp lệ (không phải NaN).
data.dropna()


data[data.notna()] # Lọc dữ liệu: Chọn ra các phần tử trong Series 'data' KHÔNG phải là NaN (ngược lại của .isna()), loại bỏ các giá trị thiếu.


# Tạo một DataFrame 4x3 chứa các giá trị số và giá trị thiếu (NaN)
data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan],
                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])
data # Hiển thị DataFrame

# Loại bỏ các HÀNG (rows) chứa bất kỳ giá trị thiếu (NaN) nào: Chỉ giữ lại các hàng hoàn toàn không có NaN.
data.dropna()


data.dropna(how="all") # Loại bỏ các HÀNG (rows) mà TẤT CẢ các giá trị đều là NaN. Giữ lại các hàng có ít nhất một giá trị hợp lệ.


# Thêm một cột (column) mới vào DataFrame, đặt tên là '4' (do không chỉ định tên), và gán TẤT CẢ giá trị trong cột này là NaN.
data[4] = np.nan
data # Hiển thị DataFrame mới

# Loại bỏ các CỘT (columns) mà TẤT CẢ các giá trị đều là NaN (tham số axis="columns" hoặc axis=1).
# Cột '4' vừa tạo sẽ bị loại bỏ, các cột khác được giữ lại.
data.dropna(axis="columns", how="all")


# Tạo một DataFrame 7x3 chứa các số ngẫu nhiên theo phân phối chuẩn.
df = pd.DataFrame(np.random.standard_normal((7, 3)))

# Cố tình gán NaN (giá trị thiếu) vào các vị trí cụ thể:
df.iloc[:4, 1] = np.nan # Gán NaN cho 4 hàng đầu tiên (chỉ số 0 đến 3) của Cột 1.
df.iloc[:2, 2] = np.nan # Gán NaN cho 2 hàng đầu tiên (chỉ số 0 và 1) của Cột 2.
df # Hiển thị DataFrame sau khi gán NaN.

# Loại bỏ HÀNG (row) chứa bất kỳ giá trị NaN nào: Giữ lại chỉ các hàng hoàn toàn không có giá trị thiếu.
df.dropna()

# Loại bỏ HÀNG (row) mà có ít hơn 2 giá trị hợp lệ (non-NaN):
# Giữ lại các hàng có ít nhất 2 giá trị HỢP LỆ.
df.dropna(thresh=2)


df.fillna(0) # Thay thế tất cả các giá trị thiếu (NaN) trong DataFrame 'df' bằng giá trị 0.


df.fillna({1: 0.5, 2: 0}) # Điền giá trị thiếu (NaN) theo cột: Thay thế NaN trong Cột 1 bằng 0.5, và NaN trong Cột 2 bằng 0.


# Import các thư viện cần thiết
import pandas as pd
import numpy as np

# Tạo một DataFrame 6x3 chứa các số ngẫu nhiên.
df = pd.DataFrame(np.random.standard_normal((6, 3)))

# Cố tình gán NaN (giá trị thiếu) vào các vị trí cụ thể:
df.iloc[2:, 1] = np.nan # Gán NaN cho các hàng từ chỉ số 2 đến hết của Cột 1.
df.iloc[4:, 2] = np.nan # Gán NaN cho các hàng từ chỉ số 4 đến hết của Cột 2.
df # Hiển thị DataFrame sau khi gán NaN.

# Điền giá trị thiếu (NaN) bằng cách SỬ DỤNG GIÁ TRỊ HỢP LỆ TRƯỚC ĐÓ (Forward Fill).
df.fillna(method="ffill")

# Điền giá trị thiếu (NaN) bằng cách SỬ DỤNG GIÁ TRỊ HỢP LỆ TRƯỚC ĐÓ, nhưng CHỈ ĐIỀN TỐI ĐA 2 Ô NaN liên tiếp.
df.fillna(method="ffill", limit=2)


# Tạo một Series Pandas chứa các số và các giá trị thiếu (NaN)
data = pd.Series([1., np.nan, 3.5, np.nan, 7])

# Điền giá trị thiếu (NaN) bằng GIÁ TRỊ TRUNG BÌNH (.mean()) của các giá trị hợp lệ trong Series 'data'.
data.fillna(data.mean())


# Tạo một DataFrame 7x2:
# Cột 'k1' chứa chuỗi lặp lại "one", "two" cùng với một "two" bổ sung ở cuối.
# Cột 'k2' chứa các số lặp lại và duy nhất.
data = pd.DataFrame({"k1": ["one", "two"] * 3 + ["two"],
                     "k2": [1, 1, 2, 3, 3, 4, 4]})
data # Hiển thị DataFrame vừa tạo.


data.duplicated() # Kiểm tra sự trùng lặp của HÀNG (row): Trả về một Series Boolean, đánh dấu True cho các hàng đã TỪNG XUẤT HIỆN TRƯỚC ĐÓ.


data.drop_duplicates() # Loại bỏ các HÀNG (row) bị trùng lặp: Giữ lại bản sao đầu tiên (first occurrence) của mỗi hàng và loại bỏ tất cả các bản sao sau đó.


# Giả sử DataFrame 'data' đã được tạo
# data = pd.DataFrame({"k1": ["one", "two"] * 3 + ["two"],
#                      "k2": [1, 1, 2, 3, 3, 4, 4]})

# Thêm một cột mới tên là "v1" chứa các số từ 0 đến 6 (range(7)).
data["v1"] = range(7)
data # Hiển thị DataFrame mới

# Loại bỏ các HÀNG bị trùng lặp, nhưng CHỈ XEM XÉT sự trùng lặp trong CỘT "k1".
# Nghĩa là, chỉ giữ lại bản sao đầu tiên của mỗi giá trị duy nhất trong cột "k1" ("one" và "two").
data.drop_duplicates(subset=["k1"])


data.drop_duplicates(["k1", "k2"], keep="last") # Loại bỏ các HÀNG bị trùng lặp: Chỉ xem xét trùng lặp trên các cột "k1" và "k2", và giữ lại bản sao CUỐI CÙNG (last occurrence) của mỗi hàng duy nhất.


# Tạo một DataFrame 9x2:
# Cột 'food' chứa tên các loại thực phẩm (có nhiều tên bị lặp lại).
# Cột 'ounces' chứa trọng lượng tương ứng của từng món.
data = pd.DataFrame({"food": ["bacon", "pulled pork", "bacon",
                              "pastrami", "corned beef", "bacon",
                              "pastrami", "honey ham", "nova lox"],
                      "ounces": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})
data # Hiển thị DataFrame vừa tạo.


meat_to_animal = {
  "bacon": "pig",
  "pulled pork": "pig",
  "pastrami": "cow",
  "corned beef": "cow",
  "honey ham": "pig",
  "nova lox": "salmon"
}


# Áp dụng mapping: Tạo cột mới tên "animal" bằng cách sử dụng các giá trị từ cột "food"
# và tra cứu giá trị tương ứng trong mapping 'meat_to_animal'.
data["animal"] = data["food"].map(meat_to_animal)

# Hiển thị DataFrame sau khi thêm cột mới.
data


# Định nghĩa một hàm Python đơn giản: lấy giá trị 'x' và trả về giá trị tương ứng trong dictionary 'meat_to_animal'.
def get_animal(x):
    return meat_to_animal[x]

# Áp dụng mapping: Lấy từng giá trị từ cột "food", đưa vào hàm 'get_animal' để tra cứu, và trả về một Series mới chứa kết quả ánh xạ.
data["food"].map(get_animal)


# Tạo một Series Pandas chứa các số, trong đó có một số giá trị đặc biệt được coi là thiếu/lỗi (-999 và -1000).
data = pd.Series([1., -999., 2., -999., -1000., 3.])
data # Hiển thị Series vừa tạo.


# Thay thế TẤT CẢ các giá trị -999 trong Series 'data' bằng giá trị thiếu chuẩn của Pandas/NumPy là NaN (Not a Number).
data.replace(-999, np.nan)


# Thay thế nhiều giá trị: Thay thế TẤT CẢ các giá trị -999 và -1000 trong Series 'data' bằng giá trị thiếu chuẩn là NaN.
data.replace([-999, -1000], np.nan)


# Thay thế nhiều giá trị bằng nhiều giá trị khác:
# - Thay thế TẤT CẢ các giá trị -999 bằng NaN (giá trị thiếu chuẩn).
# - Thay thế TẤT CẢ các giá trị -1000 bằng 0.
data.replace([-999, -1000], [np.nan, 0])


# Thay thế nhiều giá trị bằng dictionary:
# - Thay thế TẤT CẢ các giá trị -999 bằng NaN.
# - Thay thế TẤT CẢ các giá trị -1000 bằng 0.
data.replace({-999: np.nan, -1000: 0})


# Tạo một DataFrame 3x4:
# - Dữ liệu: Các số nguyên từ 0 đến 11, được sắp xếp thành 3 hàng và 4 cột (dùng np.arange(12).reshape((3, 4))).
# - Chỉ số hàng (index): "Ohio", "Colorado", "New York".
# - Tên cột (columns): "one", "two", "three", "four".
data = pd.DataFrame(np.arange(12).reshape((3, 4)),
                    index=["Ohio", "Colorado", "New York"],
                    columns=["one", "two", "three", "four"])


# Định nghĩa một hàm: lấy một chuỗi 'x', cắt lấy 4 ký tự đầu tiên (x[:4]), và chuyển chúng thành chữ IN HOA (.upper()).
def transform(x):
    return x[:4].upper()

# Áp dụng hàm 'transform' cho TẤT CẢ các nhãn (labels) trong chỉ mục hàng (index) của DataFrame 'data'.
# Kết quả trả về một Series mới chứa các nhãn đã được biến đổi.
data.index.map(transform)


# sau đó GÁN KẾT QUẢ TRỞ LẠI cho index, THAY ĐỔI VĨNH VIỄN tên của các hàng.
data.index = data.index.map(transform)

# Hiển thị DataFrame sau khi index đã được đổi tên.
data


# - index=str.title: Áp dụng hàm str.title (viết hoa chữ cái đầu) cho TẤT CẢ nhãn hàng.
# - columns=str.upper: Áp dụng hàm str.upper (viết IN HOA tất cả) cho TẤT CẢ nhãn cột.
# Trả về một DataFrame MỚI với nhãn đã được đổi tên (không sửa DataFrame gốc).
data.rename(index=str.title, columns=str.upper)


data.rename(index={"OHIO": "INDIANA"},
            columns={"three": "peekaboo"})


ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]


# Định nghĩa các điểm cắt: Tạo một list chứa các giới hạn trên của các khoảng tuổi (18, 25, 35, 60, 100).
bins = [18, 25, 35, 60, 100]

# Phân loại dữ liệu (Binning): Cắt Series 'ages' thành các khoảng (bin) được xác định bởi list 'bins'.
# Hàm pd.cut() tạo ra một đối tượng Categorical (thể hiện các danh mục tuổi).
age_categories = pd.cut(ages, bins)

# Hiển thị kết quả: In ra Series mới chứa các khoảng phân loại (ví dụ: (18, 25], (25, 35], ...).
age_categories


age_categories.codes # Trích xuất các mã số nguyên (integers) thể hiện danh mục cho mỗi phần tử trong Series (ví dụ: 0, 1, 2...).
age_categories.categories # Trích xuất các nhãn danh mục (Categorical labels) duy nhất, được sắp xếp (ví dụ: (18, 25], (25, 35], ...).
age_categories.categories[0] # Lấy nhãn danh mục đầu tiên từ danh sách categories.
pd.value_counts(age_categories) # Đếm tần suất: Đếm số lượng phần tử rơi vào mỗi danh mục (bin) và trả về kết quả theo thứ tự từ lớn đến bé.


# Tham số 'right=False' làm cho các khoảng là BÁN KÍN ở phía bên phải (trái đóng, phải mở): [a, b).
# Nghĩa là, giá trị BÊN TRÊN (giới hạn phải) sẽ KHÔNG được bao gồm trong khoảng.
pd.cut(ages, bins, right=False)


# Định nghĩa nhãn cho các khoảng (bin) sau khi phân loại.
group_names = ["Youth", "YoungAdult", "MiddleAged", "Senior"]

# Phân loại dữ liệu (Binning): Cắt Series 'ages' thành các khoảng được xác định bởi 'bins'.
# Tham số 'labels=group_names' gán tên danh mục cho các khoảng thay vì hiển thị giới hạn số mặc định.
pd.cut(ages, bins, labels=group_names)


# Tạo một mảng NumPy 1 chiều chứa 20 số ngẫu nhiên, phân phối đồng đều trong khoảng [0, 1).
data = np.random.uniform(size=20)

# Phân loại dữ liệu (Binning): Cắt Series 'data' thành 4 khoảng (bin) CÓ KÍCH THƯỚC BẰNG NHAU.
# Tham số 'precision=2' làm tròn các điểm giới hạn của khoảng (bin edges) đến 2 chữ số thập phân.
pd.cut(data, 4, precision=2)


# Tạo một mảng NumPy 1 chiều chứa 1000 số ngẫu nhiên theo phân phối chuẩn (Standard Normal Distribution).
data = np.random.standard_normal(1000)

# Phân vị (Quantile Binning): Cắt Series 'data' thành 4 khoảng (tứ phân vị - quartiles) CÓ SỐ LƯỢNG PHẦN TỬ BẰNG NHAU.
# Tham số 'precision=2' làm tròn các điểm giới hạn của khoảng (bin edges) đến 2 chữ số thập phân.
quartiles = pd.qcut(data, 4, precision=2)
quartiles # Hiển thị Series Categorical mới (chứa các khoảng tứ phân vị).

# Đếm tần suất: Đếm số lượng phần tử rơi vào mỗi khoảng tứ phân vị (mỗi khoảng sẽ có khoảng 250 phần tử)
pd.value_counts(quartiles)


pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.]).value_counts()


# Tạo một DataFrame 1000x4 (1000 hàng, 4 cột):
# - Dữ liệu: 4000 số ngẫu nhiên theo phân phối chuẩn (Standard Normal Distribution).
data = pd.DataFrame(np.random.standard_normal((1000, 4)))

# Thống kê mô tả: Tính toán các thống kê mô tả tóm tắt cho TỪNG CỘT trong DataFrame 'data'.
# Các thống kê bao gồm: Count (Số lượng), Mean (Trung bình), Std (Độ lệch chuẩn), Min/Max, và các Tứ phân vị (25%, 50%, 75%).
data.describe()


# Chọn Cột có chỉ số 2 từ DataFrame 'data' và gán nó cho biến 'col' (Series).
col = data[2]

# Lọc dữ liệu: Chọn ra các phần tử trong Series 'col' mà giá trị tuyệt đối (.abs()) của chúng LỚN HƠN 3.
# Đây là cách để tìm ra các giá trị ngoại lai (outliers) hoặc các điểm dữ liệu bất thường.
col[col.abs() > 3]


# (data.abs() > 3): Tạo một DataFrame Boolean (True/False) nơi True chỉ ra các giá trị tuyệt đối lớn hơn 3.
# .any(axis="columns"): Kiểm tra TỪNG HÀNG (axis="columns" hoặc axis=1) trong DataFrame Boolean đó, trả về True nếu CÓ ÍT NHẤT MỘT giá trị True (tức là có ít nhất một giá trị ngoại lai).
# data[...]: Lọc DataFrame 'data' ban đầu để CHỈ giữ lại những HÀNG mà có ít nhất một giá trị ngoại lai (tức là giá trị tuyệt đối lớn hơn 3).
data[(data.abs() > 3).any(axis="columns")]


# 1. (data.abs() > 3): Tạo DataFrame Boolean, True cho các giá trị ngoại lai (giá trị tuyệt đối > 3).
# 2. np.sign(data): Trả về dấu của mỗi phần tử (1 cho dương, -1 cho âm, 0 cho 0).
# 3. np.sign(data) * 3: Nhân dấu với 3 (tức là 3.0 hoặc -3.0).
# 4. data[...] = ...: Gán giá trị 3.0 hoặc -3.0 CHO TẤT CẢ các vị trí được đánh dấu là True (giá trị ngoại lai).
# Mục đích: Thay thế tất cả các giá trị tuyệt đối > 3 bằng 3.0 hoặc -3.0, giữ nguyên dấu.
data[data.abs() > 3] = np.sign(data) * 3

# Thống kê mô tả: Tính toán lại các thống kê tóm tắt cho DataFrame sau khi đã loại bỏ/giới hạn các giá trị ngoại lai.
data.describe()


np.sign(data).head()


# Tạo một DataFrame 5x7:
# - Dữ liệu: Các số nguyên từ 0 đến 34, được sắp xếp thành 5 hàng và 7 cột (dùng np.arange(5 * 7).reshape((5, 7))).
df = pd.DataFrame(np.arange(5 * 7).reshape((5, 7)))
df # Hiển thị DataFrame vừa tạo.

# Tạo một mảng NumPy chứa 5 số nguyên từ 0 đến 4 (tương ứng với số hàng của DataFrame)
# ở trạng thái ĐƯỢC XÁO TRỘN NGẪU NHIÊN (random permutation).
# Mảng này sẽ được dùng để chọn mẫu hoặc sắp xếp lại các hàng của DataFrame.
sampler = np.random.permutation(5)
sampler # Hiển thị mảng các chỉ số đã được xáo trộn.


# Sắp xếp lại hàng bằng phương thức .take(): Lấy các hàng từ DataFrame 'df' theo thứ tự chỉ mục được chỉ định trong 'sampler'.
# Kết quả: Các hàng của DataFrame được xáo trộn ngẫu nhiên theo trật tự của 'sampler'.
df.take(sampler)

# Sắp xếp lại hàng bằng chỉ mục vị trí (.iloc): Tương đương với df.take(sampler).
# Lấy các hàng từ DataFrame 'df' theo thứ tự vị trí (integer location) được chỉ định trong 'sampler'.
df.iloc[sampler]


# Tạo một mảng NumPy chứa 7 số nguyên từ 0 đến 6 (tương ứng với số cột của DataFrame)
# ở trạng thái ĐƯỢC XÁO TRỘN NGẪU NHIÊN. Mảng này sẽ được dùng để sắp xếp lại các cột.
column_sampler = np.random.permutation(7)
column_sampler # Hiển thị mảng các chỉ số cột đã được xáo trộn.

# Sắp xếp lại CỘT (column) bằng phương thức .take(): Lấy các cột từ DataFrame 'df' theo thứ tự chỉ mục
# được chỉ định trong 'column_sampler' (axis="columns" hoặc axis=1).
# Kết quả: Các cột của DataFrame được xáo trộn ngẫu nhiên.
df.take(column_sampler, axis="columns")


df.sample(n=3) # Chọn mẫu ngẫu nhiên: Chọn ngẫu nhiên 3 HÀNG (rows) từ DataFrame 'df' (mặc định không thay thế).


# Tạo một Series Pandas chứa 5 giá trị số.
choices = pd.Series([5, 7, -1, 6, 4])

# Chọn mẫu ngẫu nhiên có THAY THẾ:
# - n=10: Chọn 10 phần tử.
# - replace=True: Cho phép MỘT PHẦN TỬ được chọn LẶP LẠI (quan trọng vì n > số phần tử ban đầu là 5).
choices.sample(n=10, replace=True)


# Tạo một DataFrame 6x2:
# - Cột "key" chứa các giá trị danh mục lặp lại ("b", "b", "a", "c", "a", "b").
# - Cột "data1" chứa các số nguyên từ 0 đến 5.
df = pd.DataFrame({"key": ["b", "b", "a", "c", "a", "b"],
                   "data1": range(6)})
df # Hiển thị DataFrame vừa tạo.

# Mã hóa One-Hot (One-Hot Encoding): Chuyển cột danh mục "key" thành các CỘT NHỊ PHÂN (dummy variables).
# - Mỗi giá trị duy nhất ("a", "b", "c") trong cột "key" trở thành một cột mới.
# - Giá trị là 1.0 (vì dtype=float) nếu hàng đó thuộc danh mục đó, ngược lại là 0.0.
pd.get_dummies(df["key"], dtype=float)


# Mã hóa One-Hot (One-Hot Encoding) và Thêm tiền tố:
# - pd.get_dummies(...): Chuyển cột danh mục "key" thành các cột nhị phân (biến giả).
# - prefix="key": Thêm tiền tố 'key_' vào tên các cột mới (ví dụ: key_a, key_b, key_c) để dễ nhận dạng.
# - dtype=float: Đặt kiểu dữ liệu của biến giả là số thập phân (1.0 hoặc 0.0).
dummies = pd.get_dummies(df["key"], prefix="key", dtype=float)

# Kết hợp DataFrame:
# - df[["data1"]]: Chọn cột "data1" (dữ liệu ban đầu) làm nền.
# - .join(dummies): Kết hợp DataFrame gốc (chỉ cột "data1") với các cột biến giả mới ('dummies') dựa trên chỉ mục hàng.
df_with_dummy = df[["data1"]].join(dummies)

# Hiển thị DataFrame kết hợp (chứa cột dữ liệu gốc và các cột biến giả).
df_with_dummy


# Định nghĩa tên cột cho DataFrame
mnames = ["movie_id", "title", "genres"]

# Đọc dữ liệu từ file "movies.dat" (file dữ liệu MovieLens):
# - sep="::": Dùng ký tự "::" làm dấu phân cách (delimiter).
# - header=None: Không có dòng tiêu đề (header) trong file.
# - names=mnames: Gán tên cột được định nghĩa bởi list 'mnames'.
# - engine="python": Bắt buộc sử dụng engine 'python' vì dấu phân cách là nhiều ký tự ("Sử dụng engine='python' vì dấu phân cách là nhiều ký tự").
movies = pd.read_table("../lap02/datasets/movielens/movies.dat", sep="::",
                       header=None, names=mnames, engine="python")

# Hiển thị 10 dòng (rows) đầu tiên của DataFrame 'movies' để kiểm tra dữ liệu.
movies[:10]


# - .str.get_dummies("|"): Tách chuỗi trong cột 'genres' bằng dấu phân cách "|" (dấu gạch đứng).
# - Mỗi thể loại duy nhất ("Action", "Adventure", v.v.) trở thành một cột nhị phân (0 hoặc 1).
dummies = movies["genres"].str.get_dummies("|")

# Hiển thị 10 hàng (rows) đầu tiên và 6 cột (columns) đầu tiên của DataFrame 'dummies' vừa tạo.
dummies.iloc[:10, :6]


# - dummies.add_prefix("Genre_"): Thêm tiền tố 'Genre_' vào tên các cột trong DataFrame 'dummies' (ví dụ: Genre_Action).
# - movies.join(...): Kết hợp DataFrame 'movies' gốc với các cột biến giả đã được đổi tên (dummies) dựa trên chỉ mục hàng (index).
movies_windic = movies.join(dummies.add_prefix("Genre_"))

# Hiển thị hàng đầu tiên (chỉ số 0) của DataFrame mới 'movies_windic'.
# Hàng này sẽ chứa thông tin phim gốc (movie_id, title, genres) KÈM THEO tất cả các cột Genre_... nhị phân (0 hoặc 1).
movies_windic.iloc[0]


# Thiết lập seed để đảm bảo các số ngẫu nhiên được tạo ra luôn giống nhau mỗi lần chạy.
np.random.seed(12345) 

# Tạo một Series chứa 10 số ngẫu nhiên, phân phối đồng đều trong khoảng [0, 1).
values = np.random.uniform(size=10)
values # Hiển thị Series các giá trị ngẫu nhiên.

# Định nghĩa các điểm cắt (bins) để chia dữ liệu thành 5 khoảng đều nhau.
bins = [0, 0.2, 0.4, 0.6, 0.8, 1]

# Phân loại (pd.cut) và Mã hóa One-Hot (pd.get_dummies):
# 1. pd.cut(values, bins): Cắt Series 'values' thành 5 khoảng (bins) đã định nghĩa.
# 2. pd.get_dummies(...): Mã hóa One-Hot (One-Hot Encoding) kết quả: Mỗi khoảng (bin) trở thành một cột nhị phân (0 hoặc 1).
pd.get_dummies(pd.cut(values, bins))


# Tạo một Series chứa các số nguyên và một giá trị thiếu (None).
# Khi kết hợp số nguyên và None (hoặc np.nan), Pandas tự động chuyển kiểu sang 'float64'
# để có thể biểu diễn giá trị thiếu (NaN).
s = pd.Series([1, 2, 3, None])
s # Hiển thị Series

# Truy cập thuộc tính .dtype để kiểm tra kiểu dữ liệu của Series.
s.dtype # Kết quả sẽ là 'float64' (hoặc tương đương)


# Tạo một Series chứa các số nguyên và một giá trị thiếu (None).
# QUAN TRỌNG: Sử dụng dtype=pd.Int64Dtype() (hoặc "Int64") để sử dụng kiểu dữ liệu Integer có hỗ trợ giá trị thiếu (nullable integer dtype).
s = pd.Series([1, 2, 3, None], dtype=pd.Int64Dtype())
s # Hiển thị Series (Lưu ý kiểu dữ liệu sau mỗi giá trị: <Int64>)

# Kiểm tra giá trị thiếu: Trả về một Series Boolean, True cho các vị trí chứa giá trị thiếu.
# Trong Series Integer có hỗ trợ giá trị thiếu, giá trị thiếu vẫn được biểu diễn là <NA> (tương đương NaN/None).
s.isna()

# Truy cập thuộc tính .dtype để kiểm tra kiểu dữ liệu của Series.
s.dtype # Kết quả sẽ là 'Int64' (kiểu Integer có hỗ trợ giá trị thiếu)


# Lấy giá trị tại chỉ mục 3 (phần tử cuối cùng) của Series 's'.
# Giá trị này được biểu diễn là <NA> (giá trị thiếu của Pandas).
s[3]

# 2. Kiểm tra giá trị thiếu:
# Kiểm tra xem giá trị s[3] (tức là <NA>) có phải là hằng số pd.NA (giá trị thiếu chuyên dụng của Pandas) hay không.
# Kết quả sẽ là True.
s[3] is pd.NA


# Tạo một Series chứa các số nguyên và một giá trị thiếu (None).
# QUAN TRỌNG: Sử dụng dtype="Int64" (viết hoa 'I') để kích hoạt kiểu dữ liệu Integer có hỗ trợ giá trị thiếu (nullable integer dtype).
s = pd.Series([1, 2, 3, None], dtype="Int64")
s # Hiển thị Series (Lưu ý kiểu dữ liệu Int64 ở cuối)


# Tạo một Series chứa các chuỗi và một giá trị thiếu (None).
# QUAN TRỌNG: Sử dụng dtype=pd.StringDtype() (hoặc "string") để kích hoạt kiểu dữ liệu String (chuỗi) có hỗ trợ giá trị thiếu.
s = pd.Series(['one', 'two', None, 'three'], dtype=pd.StringDtype())
s # Hiển thị Series (Lưu ý kiểu dữ liệu StringDtype ở cuối)


# 1. Tạo DataFrame gốc:
# DataFrame này chứa các giá trị thiếu (None) ở các cột khác nhau.
# Theo mặc định, Pandas sẽ ép kiểu cột A thành float64 và B thành object.
df = pd.DataFrame({"A": [1, 2, None, 4],
                   "B": ["one", "two", "three", None],
                   "C": [False, None, False, True]})
df # Hiển thị DataFrame gốc

# 2. Ép kiểu sang kiểu dữ liệu có thể null (Nullable Dtypes):
# - "Int64": Integer có thể null (chứa <NA> thay vì NaN).
df["A"] = df["A"].astype("Int64") 
# - "string": String có thể null (chứa <NA> thay vì None/NaN).
df["B"] = df["B"].astype("string")
# - "boolean": Boolean có thể null (chứa <NA> thay vì False/True).
df["C"] = df["C"].astype("boolean")

df # Hiển thị DataFrame sau khi ép kiểu (Lưu ý các dtype Int64, string, boolean ở cuối)


# Định nghĩa một chuỗi (string) có chứa dấu phẩy (,) và khoảng trắng không mong muốn (space).
val = "a,b, guido"
val # Hiển thị chuỗi gốc

# Tách chuỗi (split): Sử dụng phương thức .split(",") để chia chuỗi 'val' thành một list các chuỗi con,
# sử dụng dấu phẩy (,) làm dấu phân cách. Khoảng trắng sau dấu phẩy sẽ được giữ lại.
val.split(",")


pieces = [x.strip() for x in val.split(",")]
pieces


# Gán biến: Giải nén (unpacking) 3 phần tử của list 'pieces' vào 3 biến riêng biệt: first, second, và third.
first, second, third = pieces

# Nối chuỗi (String Concatenation): Nối ba chuỗi đã được gán biến với nhau,
# sử dụng ký tự "::" làm dấu phân cách (delimiter).
first + "::" + second + "::" + third


# Nối chuỗi (String Joining): Sử dụng phương thức .join() trên chuỗi "::" để nối TẤT CẢ các phần tử trong list 'pieces' lại với nhau,
# sử dụng chuỗi "::" làm dấu phân cách (delimiter) giữa các phần tử.
"::".join(pieces)


"guido" in val
val.index(",")
val.find(":")


val.index(":")


val.count(",")


val.replace(",", "::")
val.replace(",", "")


import re
text = "foo    bar\t baz  \tqux"
re.split(r"\s+", text)


regex = re.compile(r"\s+")
regex.split(text)


regex.findall(text)


text = """Dave dave@google.com
Steve steve@gmail.com
Rob rob@gmail.com
Ryan ryan@yahoo.com"""
pattern = r"[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}"

# re.IGNORECASE makes the regex case insensitive
regex = re.compile(pattern, flags=re.IGNORECASE)


regex.findall(text)


m = regex.search(text)
m
text[m.start():m.end()]


print(regex.match(text))


print(regex.sub("REDACTED", text))


pattern = r"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]{2,4})"
regex = re.compile(pattern, flags=re.IGNORECASE)


m = regex.match("wesm@bright.net")
m.groups()


regex.findall(text)


print(regex.sub(r"Username: \1, Domain: \2, Suffix: \3", text))


data = {"Dave": "dave@google.com", "Steve": "steve@gmail.com",
        "Rob": "rob@gmail.com", "Wes": np.nan}
data = pd.Series(data)
data
data.isna()


data.str.contains("gmail")


data_as_string_ext = data.astype('string')
data_as_string_ext
data_as_string_ext.str.contains("gmail")


pattern = r"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]{2,4})"
data.str.findall(pattern, flags=re.IGNORECASE)


matches = data.str.findall(pattern, flags=re.IGNORECASE).str[0]
matches
matches.str.get(1)


data.str[:5]


data.str.extract(pattern, flags=re.IGNORECASE)


values = pd.Series(['apple', 'orange', 'apple',
                    'apple'] * 2)
values
pd.unique(values)
pd.value_counts(values)


values = pd.Series([0, 1, 0, 0] * 2)
dim = pd.Series(['apple', 'orange'])
values
dim


dim.take(values)


fruits = ['apple', 'orange', 'apple', 'apple'] * 2
N = len(fruits)
rng = np.random.default_rng(seed=12345)
df = pd.DataFrame({'fruit': fruits,
                   'basket_id': np.arange(N),
                   'count': rng.integers(3, 15, size=N),
                   'weight': rng.uniform(0, 4, size=N)},
                  columns=['basket_id', 'fruit', 'count', 'weight'])
df


fruit_cat = df['fruit'].astype('category')
fruit_cat


c = fruit_cat.array
type(c)


c.categories
c.codes


dict(enumerate(c.categories))


df['fruit'] = df['fruit'].astype('category')
df["fruit"]


my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar'])
my_categories


categories = ['foo', 'bar', 'baz']
codes = [0, 1, 2, 0, 0, 1]
my_cats_2 = pd.Categorical.from_codes(codes, categories)
my_cats_2


ordered_cat = pd.Categorical.from_codes(codes, categories,
                                        ordered=True)
ordered_cat


my_cats_2.as_ordered()


rng = np.random.default_rng(seed=12345)
draws = rng.standard_normal(1000)
draws[:5]


bins = pd.qcut(draws, 4)
bins


bins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])
bins
bins.codes[:10]


bins = pd.Series(bins, name='quartile')
results = (pd.Series(draws)
           .groupby(bins)
           .agg(['count', 'min', 'max'])
           .reset_index())
results


results['quartile']


N = 10_000_000
labels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4))


categories = labels.astype('category')


labels.memory_usage(deep=True)
categories.memory_usage(deep=True)


%time _ = labels.astype('category')


%timeit labels.value_counts()
%timeit categories.value_counts()


s = pd.Series(['a', 'b', 'c', 'd'] * 2)
cat_s = s.astype('category')
cat_s


cat_s.cat.codes
cat_s.cat.categories


actual_categories = ['a', 'b', 'c', 'd', 'e']
cat_s2 = cat_s.cat.set_categories(actual_categories)
cat_s2


cat_s.value_counts()
cat_s2.value_counts()


cat_s3 = cat_s[cat_s.isin(['a', 'b'])]
cat_s3
cat_s3.cat.remove_unused_categories()


cat_s = pd.Series(['a', 'b', 'c', 'd'] * 2, dtype='category')


pd.get_dummies(cat_s, dtype=float)





pd.options.display.max_rows = PREVIOUS_MAX_ROWS



